{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adae0dd-58e2-457d-aae3-c2218e83f1fb",
   "metadata": {},
   "source": [
    "# PREPROCESSING DATA PENERBANGAN\n",
    "Margareta Valencia (A11.2022.14704)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da95323-75f8-4bc3-be4c-de099daa3e77",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e126785-c6fd-4ffe-add4-75a479d2eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a827c-3912-41a9-9442-74240b514c1c",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f19fa8f-1ae7-486b-92eb-e685338d5eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "0   0  2013      1    1     517.0             515        2.0     830.0   \n",
      "1   1  2013      1    1     533.0             529        4.0     850.0   \n",
      "2   2  2013      1    1     542.0             540        2.0     923.0   \n",
      "3   3  2013      1    1     544.0             545       -1.0    1004.0   \n",
      "4   4  2013      1    1     554.0             600       -6.0     812.0   \n",
      "\n",
      "   sched_arr_time  arr_delay  ... flight  tailnum origin dest air_time  \\\n",
      "0             819       11.0  ...   1545   N14228    EWR  IAH    227.0   \n",
      "1             830       20.0  ...   1714   N24211    LGA  IAH    227.0   \n",
      "2             850       33.0  ...   1141   N619AA    JFK  MIA    160.0   \n",
      "3            1022      -18.0  ...    725   N804JB    JFK  BQN    183.0   \n",
      "4             837      -25.0  ...    461   N668DN    LGA  ATL    116.0   \n",
      "\n",
      "   distance  hour  minute            time_hour                    name  \n",
      "0      1400     5      15  2013-01-01 05:00:00   United Air Lines Inc.  \n",
      "1      1416     5      29  2013-01-01 05:00:00   United Air Lines Inc.  \n",
      "2      1089     5      40  2013-01-01 05:00:00  American Airlines Inc.  \n",
      "3      1576     5      45  2013-01-01 05:00:00         JetBlue Airways  \n",
      "4       762     6       0  2013-01-01 06:00:00    Delta Air Lines Inc.  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('flights.csv')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890562d3-9d21-4e94-b09e-0981a8a95978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus kolom yang tidak diinginkan\n",
    "dataset.drop(['id', 'year', 'flight', 'tailnum', 'time_hour', 'minute', 'hour', 'carrier'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df04e705-3fd2-4cd9-a085-0523ec1d278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'day', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time',\n",
       "       'sched_arr_time', 'arr_delay', 'origin', 'dest', 'air_time', 'distance',\n",
       "       'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1921f-f131-40bb-8ff7-6ab79cb166aa",
   "metadata": {},
   "source": [
    "### Menghilangkan Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43dc56db-cc38-47e0-8147-f39a04868fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_delay         9430\n",
      "air_time          9430\n",
      "arr_time          8713\n",
      "dep_time          8255\n",
      "dep_delay         8255\n",
      "month                0\n",
      "day                  0\n",
      "sched_dep_time       0\n",
      "sched_arr_time       0\n",
      "origin               0\n",
      "dest                 0\n",
      "distance             0\n",
      "name                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# periksa nilai yang hilang\n",
    "print(dataset.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1deb8730-3859-48c6-9297-07776d987e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(subset=['arr_delay'], inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b28699-68ea-410f-a011-3c5636e0a124",
   "metadata": {},
   "source": [
    "### Encoding Data Kategori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d3f607-5c7d-4f07-9ade-c840104fdbcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Identify categorical columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cat_columns \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Check the number of unique categories in each categorical feature\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X[cat_columns]\u001b[38;5;241m.\u001b[39mnunique()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "cat_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Check the number of unique categories in each categorical feature\n",
    "X[cat_columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f944fe-86c9-42c0-8b5a-2cda8ed5ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of categories within each feature\n",
    "for col in cat_columns:\n",
    "    print(f\"\\nDistribution of categories in {col}:\")\n",
    "    print(X[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff614f6-c05b-4358-b5f5-1d2d055ad878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset for encoding\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# Apply one-hot encoding to 'carrier', 'origin', and 'name'\n",
    "X_encoded = pd.get_dummies(X_encoded, columns=['origin', 'name'], drop_first=True)\n",
    "\n",
    "# Apply frequency encoding to 'dest'\n",
    "dest_freq = X_encoded['dest'].value_counts() / len(X_encoded)  # calculate the frequencies\n",
    "X_encoded['dest'] = X_encoded['dest'].map(dest_freq)  # map frequencies to the feature\n",
    "\n",
    "# Show the result\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1052e98-9a95-42a4-a436-7fb6097baeb4",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173765dc-794d-4cb9-becc-8e7f555928a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "binary_cols     = [col for col in X_encoded.columns if X_encoded[col].value_counts().index.isin([0,1]).all()] \n",
    "cyclic_cols     = [col for col in X_encoded.columns if col.endswith('_cos') or col.endswith('_sin')] \n",
    "continuous_cols = [col for col in X_encoded.columns if col not in binary_cols + cyclic_cols]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the continuous features\n",
    "X_encoded[continuous_cols] = scaler.fit_transform(X_encoded[continuous_cols])\n",
    "\n",
    "# Show the result\n",
    "X_encoded.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
